Below is a **methodology-aligned, audit-safe explanation** written in the same tone and structure as your stability section. It explains **why backtesting is not applicable** without sounding defensive or speculative.

---

## Backtesting Applicability Assessment

Backtesting is typically used to evaluate whether a model’s predicted outcomes align with realized performance over time. This approach is applicable to predictive models that generate forecasts of observable events, such as default, loss, or delinquency, which can be compared against subsequent realized outcomes.

The adverse action model does not generate independent risk predictions or forecasts. Instead, it is a **methodology-based, post-hoc explainability model** designed to produce adverse action reason codes for decisions made by an upstream credit risk model. The outputs of this model consist of ranked explanatory factors derived from Shapley values, rather than predicted probabilities or outcome estimates.

Because the adverse action model does not produce outcomes that can be observed or realized in the future, there is no target variable against which predictions can be compared. As a result, traditional backtesting measures such as prediction error, calibration, or outcome alignment are not applicable to this model.

The appropriateness of the adverse action model is therefore assessed through **stability, consistency, and explainability-focused metrics**, including input and score distribution stability, stability of high-frequency decline reasons, and explanation coverage of key factors. These metrics directly evaluate whether the model explanations remain consistent, interpretable, and aligned with the upstream model decisions over time.

Based on the model’s intended use and output design, backtesting is not applicable to this methodology.


==========

Understood. Below is the **same section with all bold formatting removed**, with wording and structure unchanged.

---

Below is a fully rewritten, audit-ready section that does exactly what you asked:

• full sentences only,
• first explains what each metric monitors,
• then presents the observed results across 24Q2, 24Q4, and 25Q2,
• and ends with a combined stability assessment based strictly on the four metrics.

I have stayed factual and avoided inference or qualitative embellishment.

---

Recent Model Performance – Stability Assessment

Stability of the Reference Population Attributes

The stability of the reference population attributes evaluates whether the distributions of key input variables used in the adverse action explanations remain consistent over time. This metric is measured using Shapley-weighted Population Stability Index (PSI) values, which assess distributional shifts in the most influential input features associated with the lowest decile of applicants by model-assigned risk. Elevated PSI values would indicate changes in the characteristics of the scored population relative to the reference population used to fit the model explainers.

During 24Q2, Shapley-weighted input PSI values were below the Green threshold for all segments, with values of 0.063910 (Auto), 0.082279 (Debt Consolidation), 0.069457 (Home Improvement), and 0.077578 (Others).
During 24Q4, Shapley-weighted input PSI values remained below the Green threshold, with values of 0.063649 (Auto), 0.086057 (Debt Consolidation), 0.078869 (Home Improvement), and 0.082108 (Others).
During 25Q2, Shapley-weighted input PSI values continued to fall below the applicable Green threshold under the updated criteria, with values of 0.064459 (Auto), 0.094535 (Debt Consolidation), 0.080533 (Home Improvement), and 0.082416 (Others).

Across all three OGM periods, the input attribute distributions remained stable relative to the reference population.

---

Stability of the Reference Population Risk Scores

The stability of the reference population risk scores evaluates whether the distribution of model-assigned scores remains consistent over time when compared with the reference population used to fit the model explainers. This metric is assessed using PSI values calculated on the score distributions, focusing on the low-risk portion of the population relevant for adverse action analysis. Material score shifts could indicate changes in population risk composition or model behavior.

In 24Q2, score PSI values were below the Green threshold for all segments, with values of 0.000687 (Auto), 0.024784 (Debt Consolidation), 0.024597 (Home Improvement), and 0.016230 (Others).
In 24Q4, score PSI values remained below the Green threshold, with values of 0.000032 (Auto), 0.037488 (Debt Consolidation), 0.012860 (Home Improvement), and 0.017457 (Others).
In 25Q2, score PSI values continued to remain below the Green threshold under the updated criteria, with values of 0.000426 (Auto), 0.032549 (Debt Consolidation), 0.013990 (Home Improvement), and 0.036100 (Others).

These results indicate that the distribution of risk scores assigned by the model remained stable across all monitored periods.

---

Stability of High-Frequency Decline Reasons

The stability of high-frequency decline reasons evaluates whether the most common adverse action reason codes remain consistent between development and production environments. This metric compares the overlap of the top ten decline reasons by frequency using a count-based threshold. A reduction in overlap could indicate changes in population characteristics or shifts in model explanation behavior.

In 24Q2, the number of shared top-ten decline reasons between development and production was 8 (Auto), 9 (Debt Consolidation), 8 (Home Improvement), and 9 (Others).
In 24Q4, the number of shared top-ten decline reasons was 8 (Auto), 9 (Debt Consolidation), 8 (Home Improvement), and 8 (Others).
In 25Q2, the number of shared top-ten decline reasons was 9 (Auto), 8 (Debt Consolidation), 9 (Home Improvement), and 9 (Others).

All segments met the Green criterion in each period, indicating consistency in the most frequently reported adverse action reasons.

---

Explanation Coverage for the Top Five Key Factors

Explanation coverage for the top five key factors evaluates the extent to which the primary adverse action reasons explain the overall model output for denied applicants. This metric measures the percentage of the total Shapley contribution captured by the top five aggregated key factors. Adequate coverage indicates that the reported reasons meaningfully explain the model decision.

In 24Q2, explanation coverage exceeded 60 percent for all segments, with values of 70.6% (Auto), 68.1% (Debt Consolidation), 62.6% (Home Improvement), and 69.4% (Others).
In 24Q4, explanation coverage remained above 60 percent for all segments, with values of 70.7% (Auto), 67.6% (Debt Consolidation), 62.8% (Home Improvement), and 69.8% (Others).
In 25Q2, explanation coverage continued to exceed 60 percent for all segments, with values of 71.0% (Auto), 67.7% (Debt Consolidation), 62.7% (Home Improvement), and 69.6% (Others).

These results indicate that the majority of the model output continues to be captured by the reported key factors.

---

Overall Stability Assessment

Across 24Q2, 24Q4, and 25Q2, all four stability metrics remained within Green thresholds for every segment. The distributions of input attributes and risk scores showed no material shifts relative to the reference population, the most frequent adverse action reasons remained consistent between development and production, and explanation coverage consistently exceeded the minimum coverage threshold.

Based on the combined results of the four stability measures, the adverse action model demonstrates stable performance over the reviewed OGM periods.

---
Here is a **concise, IVR-style “Recent OGM Performance” write-up**, written in full sentences, no bold, no inference, and aligned with what is shown in the photos.

---

Recent OGM Performance

Recent OGM performance was evaluated using four stability metrics covering reference population attributes, reference population risk scores, high-frequency decline reasons, and explanation coverage for the top five key factors across 24Q2, 24Q4, and 25Q2.

Across all three OGM periods, the stability of the reference population attributes remained within Green thresholds for all segments, with Shapley-weighted input PSI values consistently below the applicable thresholds. This indicates no material change in the distribution of key input variables used in the adverse action explanations relative to the reference population.

The stability of the reference population risk scores also remained within Green thresholds across all segments and periods. Score PSI values were consistently low, indicating that the distribution of model-assigned scores remained stable over time and did not exhibit material shifts relative to the reference population.

The stability of high-frequency decline reasons was maintained throughout the monitoring periods. The number of shared top ten decline reasons between development and production met the Green criteria for all segments in each period, indicating consistency in the most frequently reported adverse action reasons.

Explanation coverage for the top five key factors exceeded the minimum threshold in all segments across all periods. The percentage of explanation coverage remained above 60 percent, indicating that the reported adverse action reasons continued to explain the majority of the model output.

Based on the combined results of these four metrics, the model demonstrated stable performance during the recent OGM periods, with no identified concerns requiring action.

=====
Here is a **concise, audit-ready Overall Model Performance Assessment**, written in full sentences, neutral tone, and consistent with IVR/MRO style. No bolding and no inference beyond the evidence shown.

---

Overall Model Performance Assessment

Overall model performance was assessed based on stability and explainability metrics appropriate for the model’s intended use. The evaluation incorporated results from recent OGM periods, including 24Q2, 24Q4, and 25Q2.

Across all reviewed periods, the model demonstrated stable performance. The reference population attributes and reference population risk scores remained consistent relative to the established reference population, with all PSI metrics falling within Green thresholds. The most frequently reported adverse action reasons remained stable between development and production environments, indicating consistent explanation behavior over time. In addition, explanation coverage for the top five key factors consistently exceeded the minimum threshold across all segments, indicating that the reported reasons continued to explain the majority of the model output.

The model does not generate independent predictions or outcome forecasts, and therefore traditional backtesting is not applicable. As a result, model performance is appropriately evaluated through stability, consistency, and explainability-focused metrics.

Based on the combined results of these assessments, the model is performing as intended, and no performance-related issues or remediation actions were identified.
